---
published: true
title:  "cs231n lec2 - 이미지 분류"
excerpt: "이미지 분류를 위한 기초적인 k-nearest, linear classifier를 다룹니다"

categories:
  - cs231n
tags:
  - [cs231n, CV]

toc: true
toc_sticky: true
 
date: 2024-09-24
last_modified_at: 2024-09-24
---
## 1. Image Classification : CV의 핵심이지만 어려운 이유.
인간의 눈으로는 매우 쉬운 일이지만 컴퓨터에게는 이미지 분류 작업이 꽤나 어려운 작업이다. 컴퓨터는 이미지의 픽셀을 숫자로 보기 때문이다. 이 숫자들은 이미지가 조금만 바뀌어도 완전히 뒤바뀌게 된다.  

이미지 분류에서 발생할 수 있는 문제점을 나열하면 아래와 같다.

![image](https://cs231n.github.io/assets/challenges.jpeg)

1. Viewpoint variation : 하나의 대상은 카메라의 방향에 따라 다양한 모습을 가진다.
2. Scale variation : 하나의 카테고리에 속하더라도 그 크기는 다양함
3. Deformation : 많은 관심 대상들이 극단적으로 기형의 자세를 취할 수 있음
4. Occlusion : 객체의 아주 일부만 식별가능한 폐색된 상태
5. Illumination conditions : 조명 효과가 급격하게 다른 경우
6. Background clutter : 관심대상이 배경과 섞여 있는 경우
7. Intra-class variation : 의자처럼 같은 대상이지만 상대적으로 다양한 모습이 존재하는 경우
   
이러한 문제점을 위해 규칙 기반 학습을 통한 이미지 분류는 매우 어렵다.
이미지에서 경계, 엣지등을 찾아내고 이들의 조합으로 고양이를 분류하더라도 이 규칙을 모든 대상마다 적용시키기 매우 어렵기 때문이다. 

이러한 문제를 해결하기 위해 최근 10 ~ 20년간 Data-driven approach에 의한 많은 발전을 이루어 왔다.

<div align = "center">
<img src ="https://github.com/user-attachments/assets/98416ff5-d6f4-43b2-8266-e8991a761a92">
</div>

1. 라벨링이 된 많은 이미지 데이터를 수집
2. 모델을 훈련
3. 훈련된 모델에게 보지 못한 새로운 이미지를 주고 평가






## 2. K-nearest neighbor Classifier : 

이미지 분류를 위한 첫번째 접근으로 `KNN classifier`를 보고 아이디어를 얻어보자.
간단히 알고리즘을 기술하면 다음과 같다.

![image](https://github.com/user-attachments/assets/08b080c8-f939-46c2-a7ec-1c0a0bec81d5)

1. 훈련 과정에서 모델에게 모든 이미지를 기억시킨다.
2. 예측 과정에서 새로운 이미지가 주어지면 기억한 이미지들과 비교하여 가장 비슷한(가까운) k개의 이미지들을 찾는다.
3. 그 이미지들의 라벨들을 majority voting을 통해 하나의 라벨을 반환한다.

`KNN classifier`는 데이터의 특성에 따라 두 객체(문서, 이미지 등) 사이의 거리 함수를 정의 하여 비교할 수만 있다면 어느 데이터든 분류할 수 있는 알고리즘이다. 매우 간단하기에 문제에 처음 적용하기에 적절하다.  

하지만 모델 훈련을 위해 벡터화된 이미지들을 메모리에 올리는데에 $O(1)$의 시간이 소요되고 예측을 위해 모든 n개의 이미지와 새로운 이미지를 전부 비교하는데 $O(n)$의 시간이 소요된다. 이는 훈련에 많은 시간이 소요되더라도 상대적으로 짧은 시간 안에 예측 결과물을 내어야 하는 현실 모델에 필요한 특성과 반대의 특성을 갖는다.  

다시 모델로 돌아와 `KNN classifier`는 훈련을 위해 고려해야할 두가지 사항이 있다.
1. 이미지 간 유사도를 측정하는 measure인 distance의 선택
2. k의 선택


### 2-1. Distance measure & K
---
'이미지 간 유사도를 어떻게 비교할 수 있을까?' 에 대한 대답으로 L1-distance를 고려할 수 있다. 비교하려는 두 이미지의 픽셀 값의 차이를 모두 구한 후 합하는 방식으로 두 이미지간 거리(유사도)를 측정할 수 있다.  

<div align = "center">

$d_{1}(I_{1}, I_{2}) = \sum_{p}{|I_{1}^{P} - I_{2}^{P} |}$ <br/>

$I_{1} \in \mathbb{R}^{1\times  (w \cdot h \cdot 3)}$ : `CIFAR-10`의 경우 $32\times 32\times 3$ 길이의 벡터<br/>

$I_{1}^{P}$ : 첫번째 이미지 $I$ 벡터의 $P$번째 원소(픽셀 값)
</div>  
L1-distance 외에도 L2-distance도 측도로 사용할 수 있다.

$$d_{2}(I_{1}, I_{2}) = \sqrt{\sum_{p}{(I_{1}^{P} - I_{2}^{P})^2}}$$


아래 사진에서 볼 수 있듯 각 좌표별 차이를 독립적으로 고려하는 L1-distance 관점에서 거리가 1인 점이 L2-distance 관점에서는 1보다 짧은 거리가 되는 경우가 있다.  

<div align = "center">
<img src="https://github.com/user-attachments/assets/12a7ec6d-4d5a-4b1d-a0ca-7c38f7cde787">
</div>
또한 L1-distance의 경우 결정경계가 축에 평행한 반면 L2-distance는 경계가 부드럽다. 이는 L1 distance의 등거리곡선(isocontour)이 직사각형인 반면 L2 distance의 경우 **모든 방향**에서 동일한 거리를 유지하는 점들의 집합인 원의 형태를 띄기 때문에 결정 경계가 곡선 형태로 나타난다.    
  

<div align = "center">
<img src="https://github.com/user-attachments/assets/a537b688-49fc-4a7e-9428-69b9d374c0e8" width="300" height="250"/>
<img src="https://github.com/user-attachments/assets/8f794051-7491-465e-a217-b4d1e6311134" width="300" height="250"/> 
</div>  

L1-distance는 좌표계에 의존하기 때문에 input vector의 원소들이 각각 중요한 의미가 있다면 (좌표계 위에 놓여있는 정보가 유의미한 정보라면) L1-ditance가 더 유효한 measure일 수 있다. 

> `CIFAR-10`의 경우 measure로 L2-distance를 선택할 경우 accuracy가 L1-distance에 비해 조금 더 낮다.

![image](https://cs231n.github.io/assets/knn.jpeg)

k가 5인 경우, 1인 경우보다 결정경계가 부드럽고 노이즈에 덜 민감한 일반화된 경계를 갖는다.
> 5-NN classifier의 흰색 부분은 2개 이상의 카테고리에 의해 동일한 vote 수를 받아 결정 경계가 모호한 경우를 의미한다.


### 2-2. Validation sets for Hyperparameter tuning
---

앞서 언급한 distance measure, k와 같은 하이퍼 파라미터 선택 문제는 데이터의 특성에 의존하므로 여러번 시도를 통해 적절한 하이퍼 파라미터를 선택해야한다.
이를 위해 데이터를 훈련, 검증, 테스트 셋 세가지로 나누고 진행하는 것이 합리적이다. 
다양한 파라미터 별로 훈련 후 검증 데이터로 검증 후 파라미터를 선택한 후 마지막에 테스트셋으로 평가하는 것이 일반적인 과정이다.

>n-fold cross-validation의 경우 데이터가 적은 경우에 유용하다. 데이터 수가 많은 deep learning task에선 computational 비용의 문제로 사용하지 않는 경우도 많다.

### 2-3. Pros and Cons of KNN classifier
---

k-nearest classifier는 현실에서 쓰지않는다. 그 이유는 아래와 같다.
1. 매우 느림
2. L1, L2 distance measure는 이미지 사이의 거리를 측정하기에 (유사도를 측정하기에) 적합하지 않음
3. 차원의 저주

data가 분포하는 공간을 구분하여 분류하는 방식이므로 train data가 많아야 특정 지역에서 dense하게 분포가능하고 그에 따라 정교하게 분류가 가능하다. 하지만, 데이터의 차원이 커질수록 비는 곳 없이 데이터를 채우려면 필요한 data수가 지수적으로 늘어난다는 차원의 저주 문제가 생긴다.


## 3. Linear Classifier : 

![image](https://cs231n.github.io/assets/imagemap.jpg)

`KNN classifier`와 달리 $f(x,w)$ 라는 함수에서 훈련데이터로 들어온 이미지로 부터 학습한 가중치 $W$와 새로운 이미지 input으로 카테고리별 예측 확률값을 반환하여 분류를 한다.
`Linear classifier`는 `KNN classifier`과 반대로 학습시간은 길지만 예측시간이 짧아 낮은 컴퓨팅 에서도 잘 작동된다.

반환된 예측 확률과 실제 정답의 함수인 Loss function을 최소화하는 방향으로 가중치 행렬 $W$를 학습한다. 학습된 가중치 행렬 $W$의 각 행에 대한 아래와 같은 두가지 해석을 할 수 있다.

1. $W$의 각 행은 각 카테고리를 나머지 카테고리와 구분하는 하나의 classifier로 생각 가능하다. 행 벡터의 원소가 바뀌면 classifier은 회전하며, 편향을 나타내는 $b$는 classifier를 선으로 해석가능하게 만든다. 

<div align = "center">
<img src = "https://cs231n.github.io/assets/pixelspace.jpeg", width = 500>
</div>

2. $W$의 각 행을 `template`로 생각할 수 있다. 새로운 이미지 벡터가 주어지면, 각 카테고리를 나타내는 행과 내적하여 점수를 구하고 가장 높은 점수를 갖는 카테고리로 이미지를 분류한다. 이 과정을 새로운 이미지에 아래 그림과 같은 모든 카테고리별 템플릿 이미지를 적용하여 가장 그럴싸한 이미지를 만들어 내는 카테고리를 선택하는 것으로 해석하는 것이다.

![image](https://cs231n.github.io/assets/templates.jpg)

`Linear Classifier`가 `CIFAR-10` 데이터로 생성해낸 템플릿 이미지를 보면, horse 템플릿의 경우 두개의 머리를 갖고 있는 것으로 보이고, car 템플릿의 경우 데이터가 대부분 빨간 자동차였음을 짐작할 수 있다. 이를 볼때 `Linear Classifier`는 말의 머리가 향한 방향이나 색깔별 자동차를 학습하기엔 너무 약한 분류기임을 알 수 있다. 이러한 복잡한 특성(비선형성) 학습이 불가한 문제는 앞으로 배울 `neural-net`을 통해 해결할 수 있을 것이다.

---
published: False
title:  "EECS 498 Lecture 3 - Linear Classifiers"
excerpt: 

categories:
  - EECS 498
tags:
  - [EECS 498, CV]

toc: true
toc_sticky: true
 
date: 2024-10-02
last_modified_at: 2024-10-02
---

## 3. Linear Classifier : 

![image](https://cs231n.github.io/assets/imagemap.jpg)

`KNN classifier`와 달리 $f(x,w)$ 라는 함수에서 훈련데이터로 들어온 이미지로 부터 학습한 가중치 $W$와 새로운 이미지 input으로 카테고리별 예측 확률값을 반환하여 분류를 한다.
`Linear classifier`는 `KNN classifier`과 반대로 학습시간은 길지만 예측시간이 짧아 낮은 컴퓨팅 에서도 잘 작동된다.

반환된 예측 확률과 실제 정답의 함수인 Loss function을 최소화하는 방향으로 가중치 행렬 $W$를 학습한다. 학습된 가중치 행렬 $W$의 각 행에 대한 아래와 같은 두가지 해석을 할 수 있다.

1. $W$의 각 행은 각 카테고리를 나머지 카테고리와 구분하는 하나의 classifier로 생각 가능하다. 행 벡터의 원소가 바뀌면 classifier은 회전하며, 편향을 나타내는 $b$는 classifier를 선으로 해석가능하게 만든다. 

<div align = "center">
<img src = "https://cs231n.github.io/assets/pixelspace.jpeg", width = 500>
</div>

2. $W$의 각 행을 `template`로 생각할 수 있다. 새로운 이미지 벡터가 주어지면, 각 카테고리를 나타내는 행과 내적하여 점수를 구하고 가장 높은 점수를 갖는 카테고리로 이미지를 분류한다. 이 과정을 새로운 이미지에 아래 그림과 같은 모든 카테고리별 템플릿 이미지를 적용하여 가장 그럴싸한 이미지를 만들어 내는 카테고리를 선택하는 것으로 해석하는 것이다.

![image](https://cs231n.github.io/assets/templates.jpg)

`Linear Classifier`가 `CIFAR-10` 데이터로 생성해낸 템플릿 이미지를 보면, horse 템플릿의 경우 두개의 머리를 갖고 있는 것으로 보이고, car 템플릿의 경우 데이터가 대부분 빨간 자동차였음을 짐작할 수 있다. 이를 볼때 `Linear Classifier`는 말의 머리가 향한 방향이나 색깔별 자동차를 학습하기엔 너무 약한 분류기임을 알 수 있다. 이러한 복잡한 특성(비선형성) 학습이 불가한 문제는 앞으로 배울 `neural-net`을 통해 해결할 수 있을 것이다.
